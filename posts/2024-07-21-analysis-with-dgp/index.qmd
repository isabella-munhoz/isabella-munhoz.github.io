---
title: "Quando os confundidores nos confundem"
description: "Usando DGP para enxergar problemas na an√°lise descritiva"
author:
  - name: Isabella Munhoz
    #url: www.isabelamunhoz.com
date: 2024-07-21
#categories: [categoria-teste] # self-defined categories
#image: cookie-image.jpeg
draft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
---

```{r}

library(dplyr)
library(ggplot2)
library(kableExtra)

my_options <- options(
  scipen = 999
)

mk_tbl <- function(data, table_title) {
  data |> 
    kable(caption = table_title, format = "html") |> 
    kable_styling(
      bootstrap_options = c("striped", "hover", "condensed", "responsive"),
      full_width = FALSE,
      position = "center"
    )
}

```

# Motiva√ß√£o

*[voc√™ pode pular essa se√ß√£o se n√£o quiser ler uma historinha antes do m√£o na massa]*

O livro [The Effect: An Introduction to Research Design and Causality](https://theeffectbook.net/){target="_blank"}, do professor Nick Huntington-Klein, tem sido meu maior companheiro atualmente. Dentre todos os t√≥picos que pude estudar desde que comecei a me aventurar pelo caminho das ci√™ncias de dados, com certeza o tema "causalidade" tem me feito refletir por horas.

Nick tem as qualidades que mais admiro em um professor: com uma linguagem din√¢mica e divertida, ele traduz temas profundos de forma simples. Com o uso de exemplos palp√°veis, ele nos auxilia a enxergar o conte√∫do te√≥rico sendo aplicado na realidade, sem perder o rigor necess√°rio. Essa habilidade tem um lugar especial no meu cora√ß√£o: como a minha forma√ß√£o acad√™mica n√£o foi em exatas, temas que s√£o explicados dessa maneira me possibilitam estudar √°reas que, anos atr√°s, julgava imposs√≠vel.

Quando comecei a trabalhar com ci√™ncia de dados, achava *[d.i.a.r.i.a.m.e.n.t.e]* que ter uma gradua√ß√£o em farm√°cia (e n√£o em alguma √°rea de exatas) era meu ponto mais fraco. Bom, n√£o posso dizer que a terapia est√° totalmente em dia e que esse sentimento j√° foi superado *[ele com certeza √© um amigo presente]*, mas, nos √∫ltimos tempos, tenho notado que o fato de ter uma forma√ß√£o em algo totalmente diferente acabou me colocando em uma posi√ß√£o de querer repassar tudo que venho estudando de um jeito que outras pessoas (que tamb√©m n√£o tem a forma√ß√£o na √°rea de dados) consigam entender. O exerc√≠cio sempre √©: *como a Isabella farmac√™utica gostaria que esse tema fosse apresentado?* De alguma maneira, minha maior fraqueza se tornou uma aliada porque, depois de passar por alguns projetos na √°rea de ci√™ncia de dados, pude sentir na pele que uma parte muito importante do nosso trabalho consiste em apresentar os resultados que chegamos para √°reas n√£o-t√©cnicas: em geral, as pessoas que realmente v√£o usar aquilo que desenvolvemos!

Depois desse pre√¢mbulo todo, deixa eu chegar no prop√≥sito desse artigo: esse ano estava trabalhando em um projeto que tinha como objetivo entender quais fatores foram importantes para um usu√°rio (da plataforma em que trabalho) assinar um determinado produto que oferecemos. Pra responder essa pergunta, usei um modelo de regress√£o que tinha algumas vari√°veis que o time de neg√≥cio envolvido no projeto julgava importantes pra explicar a convers√£o de um usu√°rio de "n√£o pagante" para "pagante". Enquanto apresentava os resultados do modelo, um colega (que trabalha nesse time para o qual est√°vamos entregando o projeto) me questionou o porqu√™ de uma vari√°vel X do modelo apresentar um efeito muito menor na convers√£o do que eles estavam esperando. Esse time em espec√≠fico tinha conduzido um estudo anterior ao meu projeto, e, em alguma an√°lise descritiva desse estudo, tinham notado que a vari√°vel X em quest√£o tinha um impacto muito diferente na convers√£o do que o impacto que est√°vamos vendo na minha modelagem. 

Quando eles me contaram como tinham feito a an√°lise nesse primeiro estudo, expliquei que o modelo de regress√£o que est√°vamos usando agora avaliava o efeito da vari√°vel X independentemente do efeito de outras vari√°veis (o que n√£o acontecia na an√°lise descritiva de m√©dias do estudo anterior). A discuss√£o sobre a diferen√ßa entre uma regress√£o e uma an√°lise descritiva acabou n√£o se aprofundando na reuni√£o e eu segui o resto da apresenta√ß√£o com aquela vozinha dentro de mim dizendo: *n√£o √© essa explica√ß√£o que a Isabella farmac√™utica gostaria de ter ouvido*. Como se essa vozinha j√° n√£o fosse chata por si s√≥, tinha uma outra dizendo: *ser√° que voc√™ entende de verdade como uma an√°lise descritiva pode levar a conclus√µes equivocadas?* 

*[s√≠ndrome do impostor, seja bem-vinda]*

Na mesma semana em que essa reuni√£o aconteceu, enquanto lia o [cap√≠tulo 5 do livro The Effect](https://theeffectbook.net/ch-Identification.html){target="_blank"}, me deparei com um exemplo que trazia, de forma resumida, um jeito de enxergar como podemos nos equivocar nas conclus√µes que tiramos quando avaliamos dados observacionais sem levar em considera√ß√£o como as vari√°veis independentes de um modelo se influenciam. E √© esse o objetivo desse artigo: trazer o exemplo que o querido professor Nick colocou no livro (e alguns outros insights que tive enquanto estudava esse cap√≠tulo) para tentar explicar de forma simples como confundidores de um modelo podem causar uma baita confus√£o.

*[achei o universo muito simp√°tico por fazer tudo se conectar em menos de 7 dias]* ü•πüôè

# Ponto de partida


# Criando o nosso universo

Vamos come√ßar simulando uma popula√ß√£o. Dado que estamos criando todas as regras de como nosso universo funciona, sabemos exatamente o processo gerador dos dados (DGP) e podemos concluir como as coisas acontecem...

No nosso mudinho, temos as seguinte regras:

-   30% dos indiv√≠duos possuem diploma
-   20% dos indiv√≠duos possuem cabelo castanho
-   O sal√°rio dos indiv√≠duos segue uma distrbui√ß√£o log-normal
-   Se um indiv√≠duo tem diploma, seu sal√°rio aumenta em 20%
-   Se um indiv√≠duo tem cabelo castanho, seu sal√°rio aumenta em 10%

```{r echo = TRUE}
#| code-fold: false

# definindo o tamanho da popula√ß√£o
pop_size <- 1000000

set.seed(123)
population <- tibble(
  # id do indiv√≠duo
  id = 1:pop_size,
  # gerando uma distribui√ß√£o binomial, com 30% de probabilidade do usu√°rio em ter um diploma
  college_degree = rbinom(pop_size, size = 1, prob = 0.3),
  # gerando uma distribui√ß√£o binomial, com 20% de probabilidade do usu√°rio em ter um cabelo castanho
  brown_hair = rbinom(pop_size, size = 1, prob = 0.2)
)

```

```{r}

# sumarizando os dados da popula√ß√£o
population |> 
  summarise(
    `college_degree%` = round((sum(college_degree) / n()) * 100, 3),
    `brown_hair%` = round((sum(brown_hair) / n()) * 100, 3)
  ) |> 
  mk_tbl(
    table_title = "Tabela 1. Porcentagem de indiv√≠duos com diploma e cabelo castanho na popula√ß√£o gerada"
  )

```

Para cada indiv√≠duo gerado na nossa popula√ß√£o, vamos calcular o sal√°rio conforme as regras estabelecidas acima.

<strong>Um pequeno par√™nteses sobre o c√°lculo do sal√°rio </strong>

Conforme dito, o sal√°rio √© log-normal. A primeira vez que pensei em como simular, foi ... Contudo, olhando no livro, o autor indicava calulcar o sal√°rio da seguinte maneira... S√≥ queria mostrar aqui que ambos os jeitos equivalem a mesma coisa...

Vamos seguir no c√≥gido calculando o sal√°rio conforme o Nick indicou...

```{r echo = TRUE}

set.seed(123)
population <- population |> 
  mutate(
    error_term = rnorm(n = pop_size, mean = 5, sd = 1),
    log_income = brown_hair * 0.1 + college_degree * 0.2 + error_term,
    income = exp(log_income)
  )

```

Imagine um pesquisador que n√£o tenha conhecimento algum sobre o processo gerador de dados dessa popula√ß√£o, mas que esteja interessado em responder a seguinte pergunta: "Pessoas com cabelo castanho possuem um sal√°rio maior do que pessoas que n√£o possuem cabelo castanho?".

Plot do sal√°rio

```{r}

population |> 
  ggplot(
    aes(
      x = income
    )
  ) +
  geom_histogram(
    aes(y = ..density..),
    bins = 1000
  ) +
  geom_density(
    color = "red"
  ) +
  theme_bw()

```

Plot do log do sal√°rio

```{r}

population |> 
  ggplot(
    aes(
      x = log_income
    )
  ) +
  geom_histogram(
    aes(y = ..density..),
    bins = 1000
  ) +
  geom_density(
    color = "red"
  ) +
  theme_bw()

```

Como sabemos que indiv√≠duos de cabelo castanho tem um sal√°rio 10% maior, esperamos ver isso nos dados...

```{r}

population |> 
  ggplot(
    aes(
      x = log_income,
      group = factor(brown_hair),
      color = factor(brown_hair)
    )
  ) +
  geom_density() +
  theme_minimal() +
  labs(
    color = "brown_hair"
  )

```

```{r}

population |> 
  summarise(
    mean_log_income = mean(log_income),
    .by = c(brown_hair)
  ) |> 
  arrange(
    brown_hair
  ) |> 
  mk_tbl(
    table_title = "Tabela X"
  )

```

Se segmentamos essa an√°lise somente para indiv√≠duos que n√£o possuem diploma, chegamos na mesma conclus√£o.

```{r}

population |> 
  filter(
    college_degree == 0
  ) |> 
  ggplot(
    aes(
      x = log_income,
      group = factor(brown_hair),
      color = factor(brown_hair)
    )
  ) +
  geom_density() +
  theme_minimal() +
  labs(
    color = "brown_hair"
  )

```

```{r}

population |> 
  filter(
    college_degree == 0
  ) |> 
  summarise(
    mean_log_income = mean(log_income),
    .by = c(brown_hair)
  ) |> 
  arrange(
    brown_hair
  ) |> 
  kable(caption = "Tabela", format = "html") |> 
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  )

```

```{r}

population |> 
  filter(
    college_degree == 1
  ) |> 
  ggplot(
    aes(
      x = log_income,
      group = factor(brown_hair),
      color = factor(brown_hair)
    )
  ) +
  geom_density() +
  theme_minimal() +
  labs(
    color = "brown_hair"
  )

```

```{r}

population |> 
  filter(
    college_degree == 1
  ) |> 
  summarise(
    mean_log_income = mean(log_income),
    .by = c(brown_hair)
  ) |> 
  arrange(
    brown_hair
  ) |> 
  kable(caption = "Tabela", format = "html") |> 
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  )

```

So far so good... Dentro dos segmentos, conseguimos notar que o sal√°rio tem a diferen√ßa esperada. Um outro jeito que podemos ver isso √© olhando para a porcentagem de indiv√≠duos de cabelo castanho na popula√ß√£o e nas segmenta√ß√£o college == 0 e college == 1. Em todos esses grupos, a quantidade de usu√°rio se mant√©m igual ao DPG (de \~20%).

Uma outra conclus√£o que podemo tirar √© que as vari√°veis college_degree e bronw_hair s√£o independentes, porque uma vari√°ve n√£o afeta a distribui√ß√£o da outra vari√°vel na popula√ß√£o.

# Criando um outro universo...

```{r}

pop_size <- 1000

diff1 <- c()
diff2 <- c()
hairs_effect <- c()
degree_effect <- c()
for (i in seq(100)) {
  
  college_degree <- rbinom(pop_size, size = 1, prob = 0.3)
  brown_hair <- rbinom(pop_size, size = 1, prob = 0.2)
  
  population <- tibble(
    id = 1:pop_size,
    college_degree = college_degree,
    brown_hair = brown_hair
  )
  
  n_aux <- nrow(filter(population, brown_hair == 0 & college_degree == 0))
  aux <- population |> 
    filter(
      brown_hair == 0 & college_degree == 0
    ) |> 
    select(
      id
    ) |> 
    mutate(
      dye_hair = rbinom(n = n_aux, size = 1, prob = 0.4)
    )
  
  population <- population |> 
    left_join(
      aux,
      by = c("id" = "id")
    ) |> 
    mutate(
      dye_hair = if_else(is.na(dye_hair), 0, dye_hair),
      hair = if_else(brown_hair == 1 | dye_hair == 1, 1, 0),
      error_term = rnorm(n = pop_size, mean = 5, sd = 1),
      log_income = hair * 0.1 + college_degree * 0.2 + error_term,
      income = exp(log_income),
      #test = exp(0.1 * brown_hair + 0.2 * college_degree + error_term)
    )
  
  diff1_ <- (mean(filter(population, hair == 1)$log_income) - mean(filter(population, hair == 0)$log_income)) * 100
  diff2_ <- (mean(filter(population, college_degree == 1 & hair == 1)$log_income) - mean(filter(population, college_degree == 1 & hair == 0)$log_income)) * 100
  
  diff1 <- c(diff1, diff1_)
  diff2 <- c(diff2, diff2_)
  
  model <- lm(
    log_income ~ hair + college_degree,
    data = population
  )
  hair_ <- unname(coef(model)[2])
  degree_ <- unname(coef(model)[3])
  hairs_effect <- c(hairs_effect, hair_)
  degree_effect <- c(degree_effect, degree_)
  
}

```

```{r}

population |> 
  summarise(
    sum(hair) / n()
  )

```

```{r}

population |> 
  filter(
    college_degree == 0
  ) |> 
  summarise(
    sum(hair) / n()
  )

```

```{r}

population |> 
  filter(
    college_degree == 1
  ) |> 
  summarise(
    sum(hair) / n()
  )

```

```{r}

hist(diff1)

```

```{r}

hist(diff2)

```

```{r}

sum(population$college_degree)
sum(population$brown_hair)

```

```{r}

population |> 
  filter(
    brown_hair == 0 & 
      college_degree == 0 
  ) |> 
  summarise(
    n = n(),
    s = sum(dye_hair),
    perc = (s / n) * 100
  )

```

```{r}

sum(population$hair)

```

```{r}

hist(hairs_effect * 100)

```

```{r}

hist(degree_effect * 100)

```
